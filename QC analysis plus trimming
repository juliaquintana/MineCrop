#!/bin/bash

# Description: Download FASTQ files from SRA and run QC with fastp, including trimming
# Author: Julia Quintana
# Date: 2025-06-24

# Set paths
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
SRA_LIST="/SRR_Acc_List.txt"
RAW_DIR="/Users/julia/Library/CloudStorage/OneDrive-UniversidadReyJuanCarlos/MADRID_URJC/PROJECTS/MineCrop/WP1/sra/raw_fastq"
QC_DIR="/Users/julia/Library/CloudStorage/OneDrive-UniversidadReyJuanCarlos/MADRID_URJC/PROJECTS/MineCrop/WP1/sra/qc_reports"

# Create output directories
mkdir -p "$RAW_DIR" "$QC_DIR"

# Loop through each accession number
while IFS= read -r accession; do
    echo "üîΩ Downloading $accession..."
    
    if prefetch "$accession"; then
        fasterq-dump "$accession" -O "$RAW_DIR" -t "$RAW_DIR"

        echo "üî¨ Running fastp QC for $accession..."
        # Run fastp QC
        fastp \
        -i "$RAW_DIR/${accession}_1.fastq" \
        -I "$RAW_DIR/${accession}_2.fastq" \
        -o "$QC_DIR/${accession}_1.clean.fastq" \
        -O "$QC_DIR/${accession}_2.clean.fastq" \
        -h "$QC_DIR/${accession}_fastp.html" \
        -j "$QC_DIR/${accession}_fastp.json" \
        --detect_adapter_for_pe \
        --trim_front1 15 \
        --trim_front2 15 \
        --thread 4

        # Compress cleaned FASTQ files
        echo "üì¶ Compressing cleaned FASTQ files..."
        gzip "$QC_DIR/${accession}_1.clean.fastq"
        gzip "$QC_DIR/${accession}_2.clean.fastq"
        
# Upload to Google Cloud Storage
        echo "‚òÅÔ∏è Uploading QC results to Google Cloud..."
        gsutil -m cp -r "$QC_DIR/${accession}_fastp.html" "$QC_DIR/${accession}_fastp.json" "$QC_DIR/${accession}_1.clean.fastq" "$QC_DIR/${accession}_2.clean.fastq" gs://srastorage/Triticum_root/QC

# Clear the cache
        echo "üßπ Clearing cache..."
        cache-mgr --clear
        echo "Cleared cache for $accession."
    else
        echo "‚ùå Failed to prefetch $accession"
    fi

    echo "‚úÖ Done with $accession"
done < "$SRA_LIST"
